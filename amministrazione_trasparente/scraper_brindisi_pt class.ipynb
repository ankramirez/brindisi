{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,date\n",
    "from functools import wraps\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, NoSuchWindowException, StaleElementReferenceException, InvalidSessionIdException\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from selenium.webdriver.support.ui import Select, WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "import csv\n",
    "import hashlib\n",
    "import logging\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import pdb\n",
    "import threading\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comune = 'brindisi'\n",
    "download_path = './pt'\n",
    "url_comune = 'https://servizi.comune.brindisi.it/openweb/trasparenza/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry(max_attempts=3, delay=10, exceptions=(Exception,)):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            attempts = 0\n",
    "            while attempts < max_attempts:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except exceptions as e:\n",
    "                    attempts += 1\n",
    "                    logging.info(f\"Attempt {attempts} failed:\", e)\n",
    "                    time.sleep(delay)\n",
    "            raise RuntimeError(f\"Function {func.__name__} failed after {max_attempts} attempts\")\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions = ('.pdf', '.odt', '.xls', '.csv', '.ods', '.xlsx', '.doc', '.zip', '.docx', '.sxc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebDriverManager:\n",
    "    def __init__(self, DIR_DOWNLOAD):\n",
    "        self.driver = None\n",
    "        self.output = DIR_DOWNLOAD\n",
    "\n",
    "    def start_driver(self, url):\n",
    "        if not self.driver or (self.is_driver_open() == False):\n",
    "            opts = Options()\n",
    "            # start driver\n",
    "            s = Service(r\".\\chromedriver.exe\")\n",
    "            prefs = {\"download.default_directory\": f'{self.output}',\n",
    "                    \"directory_upgrade\": True,\n",
    "                    \"profile.default_content_settings.popups\": 0}\n",
    "            opts.add_experimental_option(\"prefs\", prefs)\n",
    "            self.driver = Chrome(service=s, options=opts)\n",
    "\n",
    "            # opts = Options()\n",
    "            # service = Service()\n",
    "\n",
    "            # prefs = {\"download.default_directory\": f'{self.output}',\n",
    "            #         \"directory_upgrade\": True,\n",
    "            #         \"profile.default_content_settings.popups\": 0,\n",
    "            #         \"plugins.always_open_pdf_externally\": True\n",
    "            #         }\n",
    "\n",
    "            # opts.add_experimental_option('prefs', prefs)\n",
    "            # opts.add_argument('--no-sandbox')\n",
    "            # opts.add_argument('--headless')\n",
    "            # opts.add_argument('--disable-gpu')\n",
    "            # opts.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "            # self.driver = Chrome(service=service,\n",
    "            #                 options=opts)\n",
    "\n",
    "            self.driver.get(url)\n",
    "            time.sleep(10) # Waiting for main page to load\n",
    "        return self.driver  # Return the driver instance     \n",
    "\n",
    "    def is_driver_open(self):\n",
    "        if self.driver:\n",
    "            try:\n",
    "                # Access a property or method of the driver\n",
    "                self.driver.current_url\n",
    "                return True\n",
    "            except NoSuchWindowException:\n",
    "                return False\n",
    "            except Exception as e:\n",
    "                logging.info(f'Driver seems to be closed: {e}')\n",
    "                return False\n",
    "        return False\n",
    "    \n",
    "    def get_driver(self, link):\n",
    "        if not self.is_driver_open():\n",
    "            logging.warning(f'Driver is not responding, reopening')\n",
    "            self.driver = self.start_driver(link)\n",
    "        else: \n",
    "            logging.info('Driver is running, getting items from current section page')\n",
    "            self.driver.get(link)\n",
    "        return self.driver\n",
    "\n",
    "    def close_driver(self):\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "            self.driver = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize webdriver, and clicking on cookies button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Driver is not responding, reopening\n"
     ]
    }
   ],
   "source": [
    "driver_manager = WebDriverManager(download_path)\n",
    "driver = driver_manager.get_driver(link=url_comune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body_e = driver.find_element(By.ID, 'lista_trasparenza_categorie')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections_e = body_e.find_elements(By.TAG_NAME, 'h3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s_e in sections_e:\n",
    "#     s_name = s_e.text\n",
    "#     a_e = s_e.find_element(By.TAG_NAME, 'a')\n",
    "#     s_link = a_e.get_attribute('href')\n",
    "#     print(f'{s_name}: {s_link}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sections() -> dict:\n",
    "    sections = {}\n",
    "    driver.get(url_comune)\n",
    "    body_e = driver.find_element(By.ID, 'lista_trasparenza_categorie')\n",
    "    div_e = body_e.find_elements(By.XPATH, './div')\n",
    "\n",
    "    for d_e in div_e:\n",
    "        s_e = d_e.find_element(By.TAG_NAME, 'h3')\n",
    "        s_name = s_e.text\n",
    "        s_a_e = s_e.find_element(By.TAG_NAME, 'a')\n",
    "        s_link = s_a_e.get_attribute('href')\n",
    "\n",
    "        sections[s_name] = {'href': s_link}\n",
    "    \n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections = get_sections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsections(s_link: str) -> dict:\n",
    "    driver.get(s_link)\n",
    "    try:\n",
    "        subsections = {}\n",
    "        body_e = driver.find_element(By.ID, 'lista_servizi_privati')\n",
    "        div_e = body_e.find_elements(By.XPATH, './div')\n",
    "        for d_e in div_e:\n",
    "            a_e = d_e.find_element(By.TAG_NAME, 'a')\n",
    "            ss_name = a_e.text\n",
    "            ss_link = a_e.get_attribute('href')\n",
    "\n",
    "            subsections[ss_name] = {'href': ss_link}\n",
    "        return subsections\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s, s_values in sections.items():\n",
    "#     s_link = s_values['href']\n",
    "#     print(f'{s}: {s_link}')\n",
    "#     subsections = get_subsections(s_link=s_link)\n",
    "#     if subsections:\n",
    "#         for ss, ss_values in subsections.items():\n",
    "#             ss_link = ss_values['href']\n",
    "#             print(f'\\t{ss}: {ss_link}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SectionsTableFileExtractor:\n",
    "    def __init__(self, \n",
    "                 driver_manager, \n",
    "                 link_section:str, \n",
    "                 dir_download: str, \n",
    "                 last_date_update: datetime,\n",
    "                 files_in_db: list[str]):\n",
    "        self.driver             = driver_manager.get_driver(link=link_section)\n",
    "        self.link_section       = link_section\n",
    "        self.dir_download       = self.check_dir_download(dir_download)\n",
    "        self.last_date_update   = last_date_update\n",
    "        self.dict_links_oggetti = self.loop_all_pages()\n",
    "        self.files_in_db        = files_in_db\n",
    "\n",
    "    def check_dir_download(self, dir_download):\n",
    "        # Creating directory if does not exist:\n",
    "        if not os.path.exists(dir_download):\n",
    "            os.makedirs(dir_download)\n",
    "        return dir_download\n",
    "\n",
    "    def get_n_atto(self, ogg_e: WebElement)->str:\n",
    "        try:\n",
    "            nr_atto_div = ogg_e.find_element(By.XPATH, './/div[label[text()=\"Nr. Atto:\"]]')\n",
    "            nr_atto_text = nr_atto_div.text.split('Nr. Atto:')[-1].strip()\n",
    "            return nr_atto_text\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            logging.warning(f'SectionsTable: Could not get n_atto: {e}')\n",
    "    \n",
    "    def get_start_date(self, ogg_e: WebElement)->str:\n",
    "        try:\n",
    "            data_atto_div = ogg_e.find_element(By.XPATH, './/div[label[text()=\"Data Atto:\"]]')\n",
    "            data_atto_text = data_atto_div.text.split('Data Atto:')[-1].strip()\n",
    "            return data_atto_text\n",
    "        except NoSuchElementException:\n",
    "            try:\n",
    "                data_atto_div = ogg_e.find_element(By.XPATH, './/div[label[text()=\"Data inizio:\"]]')\n",
    "                data_atto_text = data_atto_div.text.split('Data inizio:')[-1].strip()\n",
    "\n",
    "                return data_atto_text\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                logging.warning(f'SectionsTable: Could not get start date: {e}')\n",
    "\n",
    "\n",
    "    def get_end_date(self, ogg_e: WebElement)->str:\n",
    "        try:\n",
    "            data_atto_div = ogg_e.find_element(By.XPATH, './/div[label[text()=\"Data fine:\"]]')\n",
    "            data_atto_text = data_atto_div.text.split('Data fine:')[-1].strip()\n",
    "\n",
    "            return data_atto_text\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            logging.warning(f'SectionsTable: Could not get end date: {e}')\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_oggetto_link(ogg_e: WebElement)->str:\n",
    "        try:\n",
    "            a_element = ogg_e.find_element(By.TAG_NAME, 'a')\n",
    "            return a_element.get_attribute('href')\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.warning(f'SectionsTable: Could not get link from oggetto {e}')\n",
    "        pass\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def rename_file(file_name:str, link_ogg: str)->str:\n",
    "        # Generate a unique identifier for the file\n",
    "        id = hashlib.sha256(link_ogg.encode()).hexdigest()[:8]\n",
    "\n",
    "        return f'{id}_{file_name}'\n",
    "    \n",
    "\n",
    "    def get_main_info_oggetto(self, ogg_e: WebElement) -> dict:\n",
    "        n_atto     = self.get_n_atto(ogg_e=ogg_e)\n",
    "        start_date = self.get_start_date(ogg_e=ogg_e)\n",
    "        end_date   = self.get_end_date(ogg_e=ogg_e)\n",
    "        link       = self.get_oggetto_link(ogg_e=ogg_e)\n",
    "        \n",
    "        return {link: dict(n_atto=n_atto,\n",
    "                           start_date=start_date,\n",
    "                           end_date=end_date)}\n",
    "\n",
    "\n",
    "    def get_atti_from_page(self) -> dict:\n",
    "        try:\n",
    "            all_oggetti_page = {}\n",
    "            # Waiting for the tabella element\n",
    "            body_e = WebDriverWait(self.driver, 10).until(\n",
    "                EC.presence_of_element_located((By.ID, 'table_delibere'))\n",
    "            )\n",
    "\n",
    "            # Getting each row, one for each atto\n",
    "            rows_e = body_e.find_elements(By.CLASS_NAME, 'paginated_element')\n",
    "\n",
    "            # Process rows, one for atto\n",
    "            if rows_e:\n",
    "                for r_e in rows_e:\n",
    "                    try:\n",
    "                        start_date = self.get_start_date(r_e)\n",
    "                        if (self.last_date_update == None) or (self.last_date_update < start_date.date()):\n",
    "                            dict_ogg = self.get_main_info_oggetto(ogg_e=r_e)\n",
    "\n",
    "                            all_oggetti_page.update(dict_ogg)\n",
    "                        else:  # atto already in DB, skipping it\n",
    "                            pass\n",
    "                    except StaleElementReferenceException:  # Skip this row if it became stale\n",
    "                        continue\n",
    "            else:\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            logging.warning(f'SectionsTable: Could not get the atti from this page: {e}')\n",
    "\n",
    "        return all_oggetti_page\n",
    "\n",
    "\n",
    "    def loop_all_pages(self) -> dict:\n",
    "        all_oggetti_dict = {}\n",
    "        self.driver.get(self.link_section)\n",
    "\n",
    "        page_number = 1\n",
    "        while True:\n",
    "            try:\n",
    "                logging.info(f'Getting atti from page: {page_number}')\n",
    "                dict_page = self.get_atti_from_page()\n",
    "                all_oggetti_dict.update(dict_page)\n",
    "\n",
    "                # Finding next page button\n",
    "                next_button = WebDriverWait(self.driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//a[@class='button' and @title='Successiva']\"))\n",
    "                )\n",
    "\n",
    "                # Use JavaScript to click\n",
    "                self.driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                page_number += 1\n",
    "\n",
    "                # Waiting for the new content to load\n",
    "                time.sleep(2)\n",
    "\n",
    "            except Exception as e:\n",
    "                # print(\"No more pages or an error occurred:\", e)\n",
    "                break\n",
    "        return all_oggetti_dict\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def get_filename_from_cd(cd):\n",
    "        if not cd:\n",
    "            return None\n",
    "        fname = None\n",
    "        if 'filename=' in cd:\n",
    "            fname = cd.split('filename=')[1]\n",
    "            if '\"' in fname:\n",
    "                fname = fname.split('\"')[1]\n",
    "            else:\n",
    "                fname = fname.split(';')[0].strip()\n",
    "        return fname\n",
    "    \n",
    "\n",
    "    def general_download(self, link_file:str)->Path:\n",
    "        try: \n",
    "            response = requests.get(link_file)\n",
    "\n",
    "            cd = response.headers.get('Content-Disposition')\n",
    "            b_name = self.get_filename_from_cd(cd)\n",
    "            file_name = self.rename_file(b_name, link_file) if b_name else link_file.split('/')[-1]\n",
    "\n",
    "            # Construct the full path of the file\n",
    "            file_path = Path(self.dir_download, file_name)\n",
    "            \n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            \n",
    "            return file_name, link_file, file_path\n",
    "        except Exception as e:\n",
    "            logging.info(f'SectionsTable: Could not download file from {link_file}: {e}')\n",
    "    \n",
    "\n",
    "    def download_single_file_external_page(self, link_file_external: str) -> None:\n",
    "        try:\n",
    "            self.driver.get(link_file_external)\n",
    "            scarica_button = self.driver.find_element(By.CLASS_NAME, 'btn.btn-primary')\n",
    "            link_full = scarica_button.get_attribute('href')\n",
    "            link_file = link_full.split('&CSRF')[-2]\n",
    "\n",
    "            # This is a PDF file, download it\n",
    "            f_name, f_link, f_path = self.general_download(link_file=link_file)\n",
    "            return f_name, f_link, f_path\n",
    "        except Exception as e:\n",
    "            logging.info(f'SectionsTable: Could not get file from external link: {e}')\n",
    "\n",
    "\n",
    "    def download_single_file_atto_page(self, link_ogg: str) -> Tuple[str, str, str]:\n",
    "        \"\"\"This method will get all the links available for a given atto, it will use the HEAD request \n",
    "        to check if it's possible to download a file from the given file, otherwise it probably it's an \n",
    "        external link, in this case it will open the external link and download the files from it.\n",
    "\n",
    "        Args:\n",
    "            link_ogg (str): Link of the atto.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[str, str, str]: Name of the file, Link of the file, Path where it's been saved.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Send a HEAD request to check the content type\n",
    "            response = requests.head(link_ogg, allow_redirects=True)\n",
    "            \n",
    "            if 'Content-Type' in response.headers: \n",
    "                content_type = response.headers['Content-Type']\n",
    "                # If the link has the file, download it\n",
    "                if 'application/pdf' in content_type:\n",
    "                    f_name, f_link, f_path = self.general_download(link_file=link_ogg)\n",
    "                # Else maybe it's an external link, try to download it:\n",
    "                else:\n",
    "                    f_name, f_link, f_path = self.download_single_file_external_page(link_file_external=link_ogg)\n",
    "                return f_name, f_link, f_path\n",
    "            else:\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            logging.warning(f'SectionsTable: Could not download files from {link_ogg}: {e}')\n",
    "            return None, None, None\n",
    "        \n",
    "\n",
    "    def get_single_object(self, link_ogg: str, dict_info: dict, dict_ogg: dict):\n",
    "        try:\n",
    "            body_e = self.driver.find_element(By.ID, 'allegati')\n",
    "            list_link_e = body_e.find_elements(By.TAG_NAME, 'a')\n",
    "            list_link = [l_e.get_attribute('href') for l_e in list_link_e]\n",
    "\n",
    "            for l in list_link:\n",
    "                f_name, f_link, f_path = self.download_single_file_atto_page(l)\n",
    "                if f_name and f_link and f_path and (f_name not in self.files_in_db):\n",
    "                    dict_ogg[f_name] = dict(**dict_info,\n",
    "                                            file_name     = f_name,\n",
    "                                            link          = f_link,\n",
    "                                            internal_path = f_path)\n",
    "        except Exception as e:\n",
    "            logging.warning(f'SectionsTable: Could not download files: {e}')\n",
    "\n",
    "\n",
    "    @retry(max_attempts=5, delay=10, exceptions=(StaleElementReferenceException, InvalidSessionIdException))\n",
    "    def get_single_object(self, link_ogg: str, dict_info: dict, dict_ogg: dict):\n",
    "        self.driver.get(link_ogg)\n",
    "        try:\n",
    "            body_e = self.driver.find_element(By.CLASS_NAME, 'card-body.pe-0.ps-4.ps-md-5')\n",
    "        except NoSuchElementException:\n",
    "            try:\n",
    "                body_e = self.driver.find_element(By.ID, 'allegati')\n",
    "            except:\n",
    "                logging.warning(f'SectionsTable: Could not get allegati from {link_ogg}: {e}')\n",
    "        if body_e:\n",
    "            try:\n",
    "                list_link_e = body_e.find_elements(By.TAG_NAME, 'a')\n",
    "                list_link = [l_e.get_attribute('href') for l_e in list_link_e]\n",
    "\n",
    "                for l in list_link:\n",
    "                    f_name, f_link, f_path = self.download_single_file_atto_page(l)\n",
    "                    if f_name and f_link and f_path and (f_name not in self.files_in_db):\n",
    "                        dict_ogg[f_name] = dict(**dict_info,\n",
    "                                                file_name     = f_name,\n",
    "                                                link          = f_link,\n",
    "                                                internal_path = f_path)\n",
    "            except Exception as e:\n",
    "                logging.warning(f'SectionsTable: Could not download files: {e}')\n",
    "\n",
    "    \n",
    "    def get_dict_objects(self):\n",
    "        dict_ogg = {}\n",
    "        total_oggetti = len(self.dict_links_oggetti)\n",
    "        logging.info(f'Found {total_oggetti} oggetti to process')\n",
    "\n",
    "        if self.dict_links_oggetti:\n",
    "            for index, (link, dict_info) in enumerate(self.dict_links_oggetti.items()):\n",
    "                # Log progress every 20 items\n",
    "                if index % 20 == 0 and index > 0:\n",
    "                    logging.info(f'Processing oggetto {index} of {total_oggetti}')\n",
    "                try:\n",
    "                    self.get_single_object(link_ogg  = link,\n",
    "                                           dict_info = dict_info,\n",
    "                                           dict_ogg  = dict_ogg)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            logging.info(f'Completed processing all {total_oggetti} oggetti')\n",
    "        else:\n",
    "            logging.info(f'SectionsTable: All files up-to-date!')\n",
    "        return dict_ogg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections_test = SectionsTableFileExtractor(driver_manager=driver_manager,\n",
    "#                            link_section='https://servizi.comune.brindisi.it/openweb/pratiche/registri.php?sezione=provvOrgani',\n",
    "#                            dir_download=f'{download_path}/Provvedimenti',\n",
    "#                            last_date_update=None,\n",
    "#                            files_in_db=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections_test.dict_links_oggetti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_download = sections_test.get_dict_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Driver is running, getting items from current section page\n",
      "INFO:root:Getting atti from page: 1\n"
     ]
    }
   ],
   "source": [
    "sections_test = SectionsTableFileExtractor(driver_manager=driver_manager,\n",
    "                           link_section='https://servizi.comune.brindisi.it/openweb/pratiche/registri.php?sezione=concorsi',\n",
    "                           dir_download=f'{download_path}/Concorsi',\n",
    "                           last_date_update=None,\n",
    "                           files_in_db=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://servizi.comune.brindisi.it/openweb/pratiche/bando_trasparenza.php?sezione=concorsi&id=1020&CSRF=a74fc953556b186b6a2c1039add0ac56': {'n_atto': None,\n",
       "  'start_date': None,\n",
       "  'end_date': None},\n",
       " 'https://servizi.comune.brindisi.it/openweb/pratiche/bando_trasparenza.php?sezione=concorsi&id=2266&CSRF=a74fc953556b186b6a2c1039add0ac56': {'n_atto': None,\n",
       "  'start_date': None,\n",
       "  'end_date': None}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections_test.dict_links_oggetti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Found 2 oggetti to process\n",
      "INFO:root:Completed processing all 2 oggetti\n"
     ]
    }
   ],
   "source": [
    "dict_download = sections_test.get_dict_objects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FileDataExtractor:\n",
    "#     def __init__(self, \n",
    "#                  base_name: str, \n",
    "#                  href: str, \n",
    "#                  dir_download: str,\n",
    "#                  files_in_db: list) -> dict:\n",
    "#         self.base_name    = base_name\n",
    "#         self.href         = href\n",
    "#         self.dir_download = self.check_dir_download(dir_download)\n",
    "#         self.files_in_db  = files_in_db\n",
    "#         self.response     = requests.get(href)\n",
    "#         self.id           = self.get_unique_id()\n",
    "#         self.file_name    = f'{self.id}_{self.sanitize_file_name(self.base_name)}'\n",
    "#         self.file_path    = self.download_file()\n",
    "\n",
    "#     @staticmethod\n",
    "#     def sanitize_file_name(file_name):\n",
    "#         # Replace invalid characters with underscores\n",
    "#         fixed_name = re.sub(r'[\\/:*?\"<>|]', '_', file_name)\n",
    "#         return fixed_name\n",
    "\n",
    "#     def get_unique_id(self)->str:\n",
    "#         # Generating a unique identifier for the file\n",
    "#         return hashlib.sha256(self.href.encode()).hexdigest()[:8]\n",
    "    \n",
    "#     def check_dir_download(self, dir_download):\n",
    "#         # Creating directory if does not exist:\n",
    "#         if not os.path.exists(dir_download):\n",
    "#             os.makedirs(dir_download)\n",
    "#         return dir_download\n",
    "\n",
    "#     def download_file(self):\n",
    "#         if self.file_name not in self.files_in_db:\n",
    "#             try:\n",
    "#                 # Construct the full path of the file\n",
    "#                 file_path = Path(self.dir_download, self.file_name)\n",
    "\n",
    "#                 # Save the file\n",
    "#                 with open(file_path, 'wb') as f:\n",
    "#                     f.write(self.response.content)\n",
    "\n",
    "#                 return file_path\n",
    "#             except:\n",
    "#                 logging.warning(f'Could not download file {self.href}')\n",
    "    \n",
    "#     def get_file_dict(self)->dict:\n",
    "#         if self.file_path:\n",
    "#             file_dict = dict(link=self.href,\n",
    "#                              internal_path=self.file_path)\n",
    "#             return {self.file_name: file_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SectionManager():\n",
    "#     def __init__(self, \n",
    "#                  ss_link:str, \n",
    "#                  dir_download: str, \n",
    "#                  links_visited: list,\n",
    "#                  files_in_db: list,\n",
    "#                  driver) -> None:\n",
    "#         self.ss_link        = ss_link\n",
    "#         self.dir_download   = dir_download\n",
    "#         self.links_v        = links_visited # list of links alrady scrapped\n",
    "#         self.driver         = driver\n",
    "#         self.files_in_db    = files_in_db\n",
    "#         self.files_to_write = {}\n",
    "\n",
    "\n",
    "#     def download_accordion(self) -> None:\n",
    "#         \"\"\"Downloading files from hidden menu\"\"\"\n",
    "#         # Expanding attachment menu\n",
    "#         menu_e = self.driver.find_element(By.ID, 'ui-accordion-1-header-0').find_element(By.TAG_NAME, 'a')\n",
    "#         self.driver.execute_script(\"arguments[0].click();\", menu_e)\n",
    "\n",
    "#         allegati_e = self.driver.find_element(By.CLASS_NAME, 'group-documenti.field-group-html-element.documenti')\n",
    "#         file_elements = allegati_e.find_elements(By.CLASS_NAME, 'file')\n",
    "\n",
    "#         self.get_list_elements(list_e=file_elements)\n",
    "\n",
    "\n",
    "#     def download_file_elements(self) -> None:\n",
    "#         \"\"\"Downloading files from file elements\"\"\"\n",
    "#         file_elements = self.driver.find_elements(By.CLASS_NAME, 'file')\n",
    "\n",
    "#         self.get_list_elements(list_e=file_elements)\n",
    "\n",
    "\n",
    "#     def get_list_elements(self, list_e: list[WebElement]):\n",
    "#         \"\"\"This method will take each web element, get the href attribute which \n",
    "#         contains the file name, then a unique id will be assing from the link, \n",
    "#         this file will be then saved and the dictionary of the files for the given \n",
    "#         section will be updated with the info of each file for posterior writing in the DB.\n",
    "\n",
    "#         Args:\n",
    "#             list_e (list[WebElement]): List of web elements that we will download \n",
    "#             and generate a dictionary with metadata with.\n",
    "#         \"\"\"\n",
    "#         # if len(list_e) > 0:\n",
    "#         #     logging.info(f'Found {len(list_e)} files to download')\n",
    "#         for f_e in list_e:\n",
    "#             a_e = f_e.find_element(By.TAG_NAME, 'a')\n",
    "#             link_file = a_e.get_attribute('href')\n",
    "#             if link_file.endswith(extensions):\n",
    "#                 self.get_single_element(link_file)\n",
    "#             else:\n",
    "#                 pass\n",
    "\n",
    "    \n",
    "#     def get_single_element(self, link_f) -> None:\n",
    "#         link_parts = link_f.split('/')\n",
    "#         file_name=link_parts[-1]\n",
    "\n",
    "#         file_dict = FileDataExtractor(base_name    = file_name,\n",
    "#                                       href         = link_f,\n",
    "#                                       dir_download = self.dir_download,\n",
    "#                                       files_in_db  = self.files_in_db).get_file_dict()\n",
    "        \n",
    "#         if file_dict:\n",
    "#             self.files_to_write.update(file_dict)\n",
    "\n",
    "    \n",
    "#     def get_microsections_field_items(self):\n",
    "#         subsections = {}\n",
    "#         try:\n",
    "#             # self.driver.get(ms_link) ##TODO\n",
    "#             body_e = self.driver.find_element(By.CLASS_NAME, 'field-items')\n",
    "#             a_elements = body_e.find_elements(By.TAG_NAME, 'a')\n",
    "\n",
    "#             for a_e in a_elements:\n",
    "#                 ms_link = a_e.get_attribute('href')\n",
    "\n",
    "#                 subsections[ms_link] = {'href': ms_link}\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#         return subsections\n",
    "    \n",
    "\n",
    "#     def get_microsections_field_title(self, ms_link: str) -> dict:\n",
    "#         try: \n",
    "#             # self.driver.get(ms_link) ##TODO\n",
    "#             self.driver.find_element(By.CLASS_NAME, \"view-content\")\n",
    "#         except NoSuchElementException:\n",
    "#             return {}\n",
    "        \n",
    "#         page_number = 0\n",
    "#         subsections = {}\n",
    "#         previous_links = set()\n",
    "        \n",
    "#         while True:\n",
    "#             self.driver.get(f'{ms_link}?page={page_number}')\n",
    "        \n",
    "#             try: \n",
    "#                 body_e = self.driver.find_element(By.CLASS_NAME, \"view-content\")\n",
    "#             except NoSuchElementException:\n",
    "#                 return subsections\n",
    "            \n",
    "#             content_e = body_e.find_elements(By.CLASS_NAME, 'views-field.views-field-title')\n",
    "\n",
    "#             if content_e:\n",
    "#                 current_links = set()\n",
    "#                 for c_e in content_e:\n",
    "#                     a_e = c_e.find_element(By.TAG_NAME, 'a')\n",
    "#                     ms_link = a_e.get_attribute('href')\n",
    "                    \n",
    "#                     current_links.add(ms_link)\n",
    "#                     subsections[ms_link] = {'href': ms_link}\n",
    "                \n",
    "#                 # Check if current page links are the same as previous page links\n",
    "#                 if current_links == previous_links:\n",
    "#                     return subsections\n",
    "#                 previous_links = current_links\n",
    "#             else:\n",
    "#                 return subsections\n",
    "            \n",
    "#             page_number += 1\n",
    "    \n",
    "\n",
    "#     def get_microsections_cards(self, ms_link: str) -> dict:\n",
    "#         try: \n",
    "#             # driver.get(ms_link) ## TODO\n",
    "#             self.driver.find_element(By.ID, \"views-bootstrap-grid-1\")\n",
    "#         except NoSuchElementException:\n",
    "#             return {}\n",
    "        \n",
    "#         page_number = 0\n",
    "#         subsections = {}\n",
    "#         previous_links = set()\n",
    "        \n",
    "#         while True:\n",
    "#             self.driver.get(f'{ms_link}?page={page_number}')\n",
    "        \n",
    "#             try:\n",
    "#                 body_e = self.driver.find_element(By.ID, \"views-bootstrap-grid-1\")\n",
    "#             except NoSuchElementException:\n",
    "#                 return subsections\n",
    "            \n",
    "#             cards_e = body_e.find_elements(By.CLASS_NAME, 'views-field.views-field-title')\n",
    "\n",
    "#             if cards_e:\n",
    "#                 for c_e in cards_e:\n",
    "#                     current_links = set()\n",
    "#                     a_e = c_e.find_element(By.TAG_NAME, 'a')\n",
    "#                     ms_link = a_e.get_attribute('href')\n",
    "\n",
    "#                     current_links.add(ms_link)\n",
    "#                     subsections[ms_link] = {'href': ms_link}\n",
    "\n",
    "#                     # Check if current page links are the same as previous page links\n",
    "#                     if current_links == previous_links:\n",
    "#                         return subsections\n",
    "#                     previous_links = current_links\n",
    "#             else:\n",
    "#                 return subsections\n",
    "            \n",
    "#             page_number += 1\n",
    "\n",
    "\n",
    "#     def get_all_types_microsections(self, ms_link: str) -> dict:\n",
    "#         self.driver.get(ms_link)\n",
    "#         self.links_v.append(ms_link)\n",
    "\n",
    "#         sections = self.get_microsections_field_items()\n",
    "#         if not sections:\n",
    "#             sections = self.get_microsections_cards(ms_link)\n",
    "#             if not sections:\n",
    "#                 sections = self.get_microsections_field_title(ms_link)\n",
    "\n",
    "#         return sections\n",
    "    \n",
    "\n",
    "#     def download_recursive_microsections(self, ms_link, depth=0, max_depth=10) -> None:\n",
    "#         if depth > max_depth:\n",
    "#             return \n",
    "\n",
    "#         microsections = self.get_all_types_microsections(ms_link)\n",
    "#         if microsections:\n",
    "#             for values in microsections.values():\n",
    "#                 link = values['href']\n",
    "#                 if link and ('https://www.comune.arezzo.it' in link) and (link not in self.links_v):\n",
    "#                     if link.endswith(extensions):\n",
    "#                         self.get_single_element(link_f=link)\n",
    "#                         # Adding the link to those already visited\n",
    "#                         self.links_v.append(link)\n",
    "#                     else: \n",
    "#                         try:\n",
    "#                             self.download_accordion()\n",
    "#                         except:\n",
    "#                             pass\n",
    "#                         try:\n",
    "#                             self.download_file_elements()\n",
    "#                         except:\n",
    "#                             pass\n",
    "\n",
    "#                         # links_visited.append(link)\n",
    "#                         self.download_recursive_microsections(link, depth + 1, max_depth)\n",
    "#                 else: \n",
    "#                     pass\n",
    "\n",
    "    \n",
    "#     def get_files_section(self) -> dict:\n",
    "#         self.download_recursive_microsections(ms_link=self.ss_link)\n",
    "#         return self.files_to_write\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_test = 'http://www.comune.arezzo.it/altri-contenuti'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section_manager_test = SectionManager(ss_link=s_test,\n",
    "#                                       dir_download=f'{download_path}/Altri contenuti',\n",
    "#                                       links_visited=[],\n",
    "#                                       files_in_db=[],\n",
    "#                                       driver=driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_to_write = section_manager_test.get_files_section()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AmministrazioneTrasparenteScrapper:\n",
    "#     def __init__(self, driver_manager, minio_manager, postgres_manager, url_comune: str, dir_output: str) -> None:\n",
    "#         self.url_comune       = url_comune\n",
    "#         self.driver           = driver_manager.get_driver(self.url_comune)\n",
    "#         self.driver_manager   = driver_manager\n",
    "#         self.minio_manager    = minio_manager\n",
    "#         self.postgres_manager = postgres_manager\n",
    "#         self.sections         = self.get_sections()\n",
    "#         self.output           = dir_output\n",
    "#         self.links_visited    = []\n",
    "\n",
    "\n",
    "#     def close_all_connections(self):\n",
    "#         logging.info('Closing all connections')\n",
    "#         self.driver_manager.close_driver()\n",
    "#         self.postgres_manager.close_connection()\n",
    "#         self.minio_manager.close_connection()\n",
    "\n",
    "    \n",
    "#     @retry(max_attempts=5, delay=10, exceptions=(StaleElementReferenceException, InvalidSessionIdException))\n",
    "#     def get_subsections(self, s_link: str) -> Tuple[dict, list[str]]:\n",
    "#         try:\n",
    "#             self.driver.get(s_link)\n",
    "#             time.sleep(1)\n",
    "\n",
    "#             body_e = driver.find_element(By.CLASS_NAME, 'field-items')\n",
    "#             a_elements = body_e.find_elements(By.TAG_NAME, 'a')\n",
    "\n",
    "#             if a_elements:\n",
    "#                 subsections = {}\n",
    "#                 links_download = []\n",
    "#                 for a_e in a_elements:\n",
    "#                     ss_link = a_e.get_attribute('href')\n",
    "\n",
    "#                     if not ss_link.endswith(extensions): \n",
    "#                         ss_name = a_e.text.strip()\n",
    "#                         subsections[ss_name] = ss_link\n",
    "#                     else:\n",
    "#                         links_download.append(ss_link)\n",
    "#             else:\n",
    "#                 logging.info(f'No subsections found')\n",
    "#         except NoSuchElementException:\n",
    "#             pass\n",
    "#         except Exception as e:\n",
    "#             logging.warning(f'Could not get subsections for {s_link}: {e}')\n",
    "#             pass\n",
    "\n",
    "#         return subsections, links_download\n",
    "\n",
    "    \n",
    "#     @retry(max_attempts=5, delay=10, exceptions=(StaleElementReferenceException, InvalidSessionIdException))\n",
    "#     def get_sections(self):\n",
    "#         sections = {}\n",
    "\n",
    "#         try:\n",
    "#             self.driver.get(url_comune)\n",
    "#             # Click on expand sections button\n",
    "#             expand_button = self.driver.find_element(By.ID, 'menu-lista-button')\n",
    "#             expand_button.click()\n",
    "\n",
    "#             body_e = self.driver.find_element(By.CLASS_NAME, 'nav.navbar-nav.list-group')\n",
    "#             li_elements = body_e.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "#             s_names = [li_e.text for li_e in li_elements]\n",
    "#             link_sections = [li_e.find_element(By.TAG_NAME, 'a').get_attribute('href') for li_e in li_elements]\n",
    "\n",
    "#             for s, s_link in zip(s_names, link_sections):\n",
    "#                 sections[s] = {'href': s_link}\n",
    "\n",
    "#         except Exception as e:\n",
    "#             logging.warning(f'Could not get sections')\n",
    "\n",
    "#         return sections\n",
    "    \n",
    "\n",
    "#     def get_single_element(self, link_f: str, files_to_write: dict, dir_download: str, files_in_db: list[str]) -> None:\n",
    "#         link_parts = link_f.split('/')\n",
    "#         file_name=link_parts[-1]\n",
    "\n",
    "#         file_dict = FileDataExtractor(base_name    = file_name,\n",
    "#                                       href         = link_f,\n",
    "#                                       dir_download = dir_download,\n",
    "#                                       files_in_db  = files_in_db).get_file_dict()\n",
    "        \n",
    "#         if file_dict:\n",
    "#             files_to_write.update(file_dict)\n",
    "        \n",
    "#         return files_to_write\n",
    "    \n",
    "\n",
    "#     def download_files_section(self, links_download: list[str], dir_download: str, files_in_db: list[str]) -> dict:\n",
    "#         files_to_write = {}\n",
    "#         if links_download:\n",
    "#             for l in links_download:\n",
    "#                 # Updating files_to_write: \n",
    "#                 files_to_write= self.get_single_element(link_f         = l,\n",
    "#                                                         files_to_write = files_to_write,\n",
    "#                                                         dir_download   = dir_download,\n",
    "#                                                         files_in_db    = files_in_db)\n",
    "#         return files_to_write\n",
    "\n",
    "    \n",
    "#     def get_subsections_files(self, ss_link: str, dir_download: str, files_in_db: list[str], files_section: list[str]):\n",
    "#         \"\"\"Function that gets all the files for a given subsection (that are not already present in the DB) and writes it to \n",
    "#         MinIO and postgres.\n",
    "\n",
    "#         Args:\n",
    "#             ss_link (str): Name of the given subsection\n",
    "#             dir_download (str): Directory of the subsection as a str\n",
    "#             files_in_db (list[str]): List of file names already written in the DB\n",
    "#             files_section (list[str]): A list of the links of the files in the section to be downloaded (not subsection)\n",
    "\n",
    "#         Raises:\n",
    "#             TimeoutError: If for a given section it takes more than 60 minutes, it will abort the operation\n",
    "#         \"\"\"\n",
    "#         # id_struttura = StrutturaTable(postgres_manager=self.postgres_manager,\n",
    "#         #                               sottosezione_lv1=s_name,\n",
    "#         #                               sottosezione_lv2=ss_name).get_id_struttura\n",
    "#         # files_in_db = DocumentiTable(postgres_manager=self.postgres_manager,\n",
    "#         #                              id_struttura=id_struttura).get_files_already_in_db()\n",
    "#         files_in_db = [] ##TODO remove\n",
    "\n",
    "#         files_section = self.download_files_section(links_download = files_section,\n",
    "#                                                     dir_download   = dir_download,\n",
    "#                                                     files_in_db    = files_in_db)\n",
    "#         print(files_section)\n",
    "        \n",
    "#         def abort_process():\n",
    "#             raise TimeoutError(f\"Process for subsection took too long and was aborted.\")\n",
    "        \n",
    "#         # Start the timer\n",
    "#         timer = threading.Timer(30 * 60, abort_process)\n",
    "#         timer.start()\n",
    "\n",
    "#         try:\n",
    "#             files_to_write = SectionManager(ss_link       = ss_link,\n",
    "#                                             dir_download  = dir_download,\n",
    "#                                             links_visited = self.links_visited,\n",
    "#                                             files_in_db   = files_in_db,\n",
    "#                                             driver        = self.driver).get_files_section()\n",
    "#             files_to_write.update(files_section)\n",
    "#             print(files_to_write)\n",
    "\n",
    "#             # Stop the timer if the process completes in time\n",
    "#             timer.cancel()\n",
    "\n",
    "#             # WriteFiles(id_struttura=id_struttura,\n",
    "#             #            dict_files=files_to_write,\n",
    "#             #            dir_download=self.output,\n",
    "#             #            postgres_manager=self.postgres_manager,\n",
    "#             #            minio_manager=self.minio_manager\n",
    "#             #            ).write_all_documents_to_db()\n",
    "#         except TimeoutError as e:\n",
    "#             logging.warning(e)\n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"An error occurred while processing subsection: {e}\")\n",
    "\n",
    "\n",
    "#     def get_sections_files(self):\n",
    "#         for s_name, s_values in self.sections.items():\n",
    "#             s_link = s_values['href']\n",
    "#             logging.info(f'SUBSECTION: {s_name}')\n",
    "#             subsections, links_download = self.get_subsections(s_link = s_link)\n",
    "#             for ss_name, ss_values in subsections.items():\n",
    "#                 ss_link = ss_values['href']\n",
    "#                 logging.info(f'\\tSUBSECTION: {ss_name}')\n",
    "#                 dir_dowload = f'{self.output}/{s_name.strip()}/{ss_name.strip()}'\n",
    "                \n",
    "#                 self.get_subsections_files(ss_link=ss_link,\n",
    "#                                            dir_download=dir_dowload,\n",
    "#                                            files_in_db=[],\n",
    "#                                            files_section=links_download)\n",
    "        \n",
    "#         # self.close_all_connections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amministrazione_test = AmministrazioneTrasparenteScrapper(driver_manager=driver_manager,\n",
    "#                                                           minio_manager=None,\n",
    "#                                                           postgres_manager=None,\n",
    "#                                                           url_comune=url_comune,\n",
    "#                                                           dir_output=download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amministrazione_test.sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amministrazione_test.get_subsections_files(ss_link='http://www.comune.arezzo.it/disposizioni-generali',\n",
    "#                                            dir_download=f'{download_path}/Disposizioni generali',\n",
    "#                                            files_in_db=[],\n",
    "#                                            files_section=['https://www.comune.arezzo.it/sites/default/files/gc_2022_316.pdf', \n",
    "#                                                           'https://www.comune.arezzo.it/sites/default/files/allegato_a_piao_2022_2024.pdf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
